{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline, AutoTokenizer\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from pysentimiento import create_analyzer\n",
    "import ijson\n",
    "import json\n",
    "import couchdb\n",
    "# from couchdb import *\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecimalEncoder(json.JSONEncoder):\n",
    "  def default(self, obj):\n",
    "    if isinstance(obj, Decimal):\n",
    "      return str(obj)\n",
    "    return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the sentiment analysis on each tweet\n",
    "def get_sentiment(sentiment_analyzer, tweet):\n",
    "    content = preprocess_tweet(tweet)\n",
    "    try:\n",
    "        sentiment = sentiment_analyzer.predict(content)\n",
    "    except:\n",
    "        pass\n",
    "    return sentiment.__dict__['output'], max(sentiment.__dict__['probas'].values())\n",
    "       \n",
    "        \n",
    "def couchify_tweet(tweet_json):\n",
    "    # keys_to_extract = [\"_id\", 'text', 'coordinates', 'geo', 'created_at', 'metadata', 'location', 'sentiment_label', 'sentiment_prob']\n",
    "    keys_to_exclude = [\"_rev\"]\n",
    "    json_couchified = {key: tweet_json[key] for key in tweet_json.keys() if key not in keys_to_exclude}\n",
    "    # if \"_id\" not in json_couchified:\n",
    "    #     json_couchified[\"_id\"] = json_couchified[\"id\"]\n",
    "    return json_couchified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/config.json from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\cb09766f7ba60b5f7a1bb640617b24f1499c4a6f3ab160c4a0ac171e3a377c68.008dca06003188334001a96363da79ced4944abc68d94a2f1e0db786dc5aa08b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/vocab.txt from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\973dbacfdf4c488622f01d1a226089e9e3dba130a0c3c11c2e36d49466fa40a8.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/bpe.codes from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\0e474c44ff353f3b378fb140e7e6d4431df4ec6142e8b38d584c0dbc5afc3521.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/added_tokens.json from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\fe46927817477a58ec2aa92ef52f8ee6fc9e824d054f4aa6a3c129724dc9c9b7.c1e7052e39d2135302ec27455f6db22e1520e6539942ff60a849c7f83f8ec6dc\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/special_tokens_map.json from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\9413ac0bed76140860deffa0c5a29ee4da7d49a3810da1b4b51b27f790bc9255.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/tokenizer_config.json from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\61374b71c02fdfd2929a3cdce24c242049e036624e15e18461a3a70cfc35e939.c260b44e952f7f2a825aac395f2ebbed4ac9553800d1e320af246e81a548f37c\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/config.json from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\cb09766f7ba60b5f7a1bb640617b24f1499c4a6f3ab160c4a0ac171e3a377c68.008dca06003188334001a96363da79ced4944abc68d94a2f1e0db786dc5aa08b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "Adding <mask> to the vocabulary\n",
      "loading configuration file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/config.json from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\cb09766f7ba60b5f7a1bb640617b24f1499c4a6f3ab160c4a0ac171e3a377c68.008dca06003188334001a96363da79ced4944abc68d94a2f1e0db786dc5aa08b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEG\",\n",
      "    \"1\": \"NEU\",\n",
      "    \"2\": \"POS\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"NEG\": 0,\n",
      "    \"NEU\": 1,\n",
      "    \"POS\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis/resolve/main/pytorch_model.bin from cache at C:\\Users\\Gyu/.cache\\huggingface\\transformers\\2e4719cf8d097772eb75070b88cbc56f1d3b1392fffc5f75032a389ef21d1847.16366ca1277caccb15200478349503b3336a1420ac26d44fc16763354f5a2cae\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "couchserver = couchdb.Server(\"http://dev:dev@172.26.131.7:5984/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Server 'http://172.26.131.7:5984/'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couchserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"twitter_hist2\"\n",
    "if db_name in couchserver:\n",
    "    db = couchserver[db_name]\n",
    "else:\n",
    "    db = couchserver.create(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Database 'twitter_hist2'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dict = {}\n",
    "for region in ('north', 'south', 'west', 'east'):\n",
    "    db_dict[region] = couchserver[f'twitter_{region}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "couchified_json = '{\"created_at\": \"Mon Apr 25 11:15:40 +0000 2022\", \"id\": 1518549298396667904, \"id_str\": \"1518549298396667904\", \"text\": \"@MattGault1 Your great grandfather is embarrassed. You\\\\u2019ve shamed the family Cronulla Dave. Go get a job, Covid us o\\\\u2026 https://t.co/vauRy5njgh\", \"display_text_range\": [12, 140], \"source\": \"<a href=\\\\\"http://twitter.com/download/iphone\\\\\" rel=\\\\\"nofollow\\\\\">Twitter for iPhone</a>\", \"truncated\": true, \"in_reply_to_status_id\": 1518504942356422656, \"in_reply_to_status_id_str\": \"1518504942356422656\", \"in_reply_to_user_id\": 1460448749004623874, \"in_reply_to_user_id_str\": \"1460448749004623874\", \"in_reply_to_screen_name\": \"MattGault1\", \"user\": {\"id\": 1504941184744972288, \"id_str\": \"1504941184744972288\", \"name\": \"The Colonel\", \"screen_name\": \"Mr_Wordle\", \"location\": \"Melbourne, Australia\", \"url\": null, \"description\": \"Love sport, Millie \\\\ud83d\\\\udc08 Cooper \\\\ud83d\\\\udc15 Relaxing, Online Guru, gardening & Outdoor adventures. Did someone say KFC!? #Regardsmaree \\\\ud83d\\\\ude0a\", \"translator_type\": \"none\", \"protected\": false, \"verified\": false, \"followers_count\": 26, \"friends_count\": 157, \"listed_count\": 0, \"favourites_count\": 1, \"statuses_count\": 1227, \"created_at\": \"Fri Mar 18 22:02:01 +0000 2022\", \"utc_offset\": null, \"time_zone\": null, \"geo_enabled\": true, \"lang\": null, \"contributors_enabled\": false, \"is_translator\": false, \"profile_background_color\": \"F5F8FA\", \"profile_background_image_url\": \"\", \"profile_background_image_url_https\": \"\", \"profile_background_tile\": false, \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1517751384938262528/AyQLv6kV_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1517751384938262528/AyQLv6kV_normal.jpg\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/1504941184744972288/1650781752\", \"default_profile\": true, \"default_profile_image\": false, \"following\": null, \"follow_request_sent\": null, \"notifications\": null, \"withheld_in_countries\": []}, \"geo\": null, \"coordinates\": null, \"place\": {\"id\": \"01864a8a64df9dc4\", \"url\": \"https://api.twitter.com/1.1/geo/id/01864a8a64df9dc4.json\", \"place_type\": \"city\", \"name\": \"Melbourne\", \"full_name\": \"Melbourne, Victoria\", \"country_code\": \"AU\", \"country\": \"Australia\", \"bounding_box\": {\"type\": \"Polygon\", \"coordinates\": [[[144.593742, -38.433859], [144.593742, -37.511274], [145.512529, -37.511274], [145.512529, -38.433859]]]}, \"attributes\": {}}, \"contributors\": null, \"is_quote_status\": false, \"extended_tweet\": {\"full_text\": \"@MattGault1 Your great grandfather is embarrassed. You\\\\u2019ve shamed the family Cronulla Dave. Go get a job, Covid us over, there\\\\u2019s thousands of jobs available out there https://t.co/2rchJVCRkj\", \"display_text_range\": [12, 165], \"entities\": {\"hashtags\": [], \"urls\": [], \"user_mentions\": [{\"screen_name\": \"MattGault1\", \"name\": \"Matt Gault\", \"id\": 1460448749004623874, \"id_str\": \"1460448749004623874\", \"indices\": [0, 11]}], \"symbols\": [], \"media\": [{\"id\": 1518549289735454722, \"id_str\": \"1518549289735454722\", \"indices\": [166, 189], \"media_url\": \"http://pbs.twimg.com/tweet_video_thumb/FRL4iIyagAIweVf.jpg\", \"media_url_https\": \"https://pbs.twimg.com/tweet_video_thumb/FRL4iIyagAIweVf.jpg\", \"url\": \"https://t.co/2rchJVCRkj\", \"display_url\": \"pic.twitter.com/2rchJVCRkj\", \"expanded_url\": \"https://twitter.com/Mr_Wordle/status/1518549298396667904/photo/1\", \"type\": \"animated_gif\", \"video_info\": {\"aspect_ratio\": [4, 3], \"variants\": [{\"bitrate\": 0, \"content_type\": \"video/mp4\", \"url\": \"https://video.twimg.com/tweet_video/FRL4iIyagAIweVf.mp4\"}]}, \"sizes\": {\"small\": {\"w\": 200, \"h\": 150, \"resize\": \"fit\"}, \"thumb\": {\"w\": 150, \"h\": 150, \"resize\": \"crop\"}, \"large\": {\"w\": 200, \"h\": 150, \"resize\": \"fit\"}, \"medium\": {\"w\": 200, \"h\": 150, \"resize\": \"fit\"}}}]}, \"extended_entities\": {\"media\": [{\"id\": 1518549289735454722, \"id_str\": \"1518549289735454722\", \"indices\": [166, 189], \"media_url\": \"http://pbs.twimg.com/tweet_video_thumb/FRL4iIyagAIweVf.jpg\", \"media_url_https\": \"https://pbs.twimg.com/tweet_video_thumb/FRL4iIyagAIweVf.jpg\", \"url\": \"https://t.co/2rchJVCRkj\", \"display_url\": \"pic.twitter.com/2rchJVCRkj\", \"expanded_url\": \"https://twitter.com/Mr_Wordle/status/1518549298396667904/photo/1\", \"type\": \"animated_gif\", \"video_info\": {\"aspect_ratio\": [4, 3], \"variants\": [{\"bitrate\": 0, \"content_type\": \"video/mp4\", \"url\": \"https://video.twimg.com/tweet_video/FRL4iIyagAIweVf.mp4\"}]}, \"sizes\": {\"small\": {\"w\": 200, \"h\": 150, \"resize\": \"fit\"}, \"thumb\": {\"w\": 150, \"h\": 150, \"resize\": \"crop\"}, \"large\": {\"w\": 200, \"h\": 150, \"resize\": \"fit\"}, \"medium\": {\"w\": 200, \"h\": 150, \"resize\": \"fit\"}}}]}}, \"quote_count\": 0, \"reply_count\": 0, \"retweet_count\": 0, \"favorite_count\": 0, \"entities\": {\"hashtags\": [], \"urls\": [{\"url\": \"https://t.co/vauRy5njgh\", \"expanded_url\": \"https://twitter.com/i/web/status/1518549298396667904\", \"display_url\": \"twitter.com/i/web/status/1\\\\u2026\", \"indices\": [117, 140]}], \"user_mentions\": [{\"screen_name\": \"MattGault1\", \"name\": \"Matt Gault\", \"id\": 1460448749004623874, \"id_str\": \"1460448749004623874\", \"indices\": [0, 11]}], \"symbols\": []}, \"favorited\": false, \"retweeted\": false, \"possibly_sensitive\": false, \"filter_level\": \"low\", \"lang\": \"en\", \"timestamp_ms\": \"1650885340676\", \"electric_car\": 0, \"sentiment_label\": \"NEG\", \"sentiment_prob\": 0.9816811680793762, \"_id\": \"1518549298396667904\"}'\n",
    "couchified_json = json.loads(couchified_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATIONS = {}\n",
    "LOCATIONS[\"west\"] = [144.317, -38.012, 144.856, -37.166]\n",
    "LOCATIONS[\"north\"] = [144.856, -38.012, 145.107, -37.166]\n",
    "LOCATIONS[\"east\"] = [145.115, -37.997, 145.490, -37.423]\n",
    "LOCATIONS[\"south\"] = [144.629, -38.533, 145.546, -38.012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_to_region(tweet, LOCATIONS):\n",
    "\n",
    "    if tweet['coordinates'] is not None:\n",
    "        if tweet['coordinates']['coordinates'] is not None:\n",
    "            lat, long = float(tweet['coordinates']['coordinates'][0]), float(tweet['coordinates']['coordinates'][1])\n",
    "\n",
    "            if LOCATIONS[\"west\"][0] <= lat <= LOCATIONS[\"west\"][2] and LOCATIONS[\"west\"][1] <= long <= LOCATIONS[\"west\"][3]:\n",
    "                return 'west'\n",
    "            elif LOCATIONS[\"east\"][0] <= lat <= LOCATIONS[\"east\"][2] and LOCATIONS[\"east\"][1] <= long <= LOCATIONS[\"east\"][3]:\n",
    "                return 'east'\n",
    "            elif LOCATIONS[\"south\"][0] <= lat <= LOCATIONS[\"south\"][2] and LOCATIONS[\"south\"][1] <= long <= LOCATIONS[\"south\"][3]:\n",
    "                return 'south'\n",
    "            elif LOCATIONS[\"north\"][0] <= lat <= LOCATIONS[\"north\"][2] and LOCATIONS[\"north\"][1] <= long <= LOCATIONS[\"north\"][3]:\n",
    "                return 'north'\n",
    "            else:\n",
    "                return None\n",
    "        else: \n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return lat, long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = {\n",
    "    'electric_cars': [\n",
    "        \"drive electric\", \"electric future\", \"electric car\", \"electric vehicle\", \"modelx\", \"ev conversion\",\n",
    "        \"elon musk\", \"tesla \", \"tesla life\", \"tesla car\", \"tesla roadster\", \"tesla motors\", \"tesla model\",\n",
    "        \"car charger\", \"self driving\", \"urban mobility\", \"zero emissions\", \"electric mobility\", \"emobility\",\n",
    "        \"self driving car\", \"autonomous vehicle\", \"autonomous car\", \"future car\", \"ev sales\", \"ev battery\",\n",
    "        \"autonomous driving\", \"audietron\", \"alternative fuel\", \"connected vehicle\", \"connected car\",\n",
    "        \"mahindra\"],\n",
    "    'recycling': [\n",
    "        'reuse', 'waste', 'composting', 'landfill', 'conserve', 'receptacles', 'disposal', 'recycle',\n",
    "        'biodegradable', 'yellow bin', 'e-waste', 'reusable', 'reprocessing', 'recycled', 'recyclebots',\n",
    "        'waste paper', 'carbon neutral', 'reduce'],\n",
    "    'solar': [\n",
    "        'solar', 'solar panels', 'solar battery', 'csp', 'renewable energy', 'elon musk', \n",
    "        'sun power', 'photovoltaic', 'cell', 'wind turbine', 'hydro', 'solar city', 'windmill',\n",
    "        'green energy', 'geothermal', 'biomass', 'carbon tax', 'carbon policy', 'C02 footprint', \n",
    "        'EBITDA', 'Enova', 'Diamond Energy', 'Momentum Energy', 'Aurora Energy', 'Tilt', 'WestWind',\n",
    "        'FinnBiogas', 'biogas', 'Acciona'\n",
    "    ]\n",
    "}\n",
    "keywords_dict = {}\n",
    "for topic in ('electric_cars', 'recycling', 'solar'):\n",
    "    keywords = []\n",
    "    for keyword in KEYWORDS[topic]:\n",
    "        hash = \"#\"\n",
    "        for word in keyword.split(\" \"):\n",
    "            hash += word\n",
    "        keywords.append(hash)\n",
    "    keywords += KEYWORDS[topic]\n",
    "    keywords_dict[topic] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tupload tweets\n",
      "100 \tupload tweets\n"
     ]
    }
   ],
   "source": [
    "# need to filter for search keys & language before uploading?\n",
    "uploaded = 0\n",
    "with open(\"twitter-melb.json\", \"rb\") as f:\n",
    "    tweets_json = []\n",
    "    for i, record in enumerate(ijson.items(f, \"rows.item.doc\")):\n",
    "        if i % 100 == 0:\n",
    "            print(f'{i} \\tupload tweets')\n",
    "            tweets_json = [json.loads(tweet) for tweet in tweets_json]\n",
    "            tweets_json = [couchify_tweet(tweet) for tweet in tweets_json]\n",
    "            tweets_region = [coordinates_to_region(tweet, LOCATIONS) for tweet in tweets_json]\n",
    "            tweets_json_w_region = {}\n",
    "\n",
    "            tweets_json_w_region = {\"north\":[], \"south\":[], \"east\":[], \"west\":[]}\n",
    "\n",
    "            for tweet, region in zip(tweets_json, tweets_region):\n",
    "                if region is not None:\n",
    "                    tweets_json_w_region[region].append(tweet)\n",
    "\n",
    "            for region in tweets_json_w_region.keys():\n",
    "                db_dict[region].update(tweets_json_w_region[region])\n",
    "            tweets_json = []\n",
    "            uploaded += 100\n",
    "            if i == 100:\n",
    "                break\n",
    "\n",
    "        try:\n",
    "            tweet = record\n",
    "            tweet_text = preprocess_tweet(tweet['text'])\n",
    "\n",
    "            tweet['electric_cars'] = 0\n",
    "            tweet['recycling'] = 0\n",
    "            tweet['solar'] = 0\n",
    "\n",
    "            for topic in keywords_dict.keys():\n",
    "                keywords = keywords_dict[topic]\n",
    "                if any(word in tweet['text'] for word in keywords):    \n",
    "                    tweet[topic] = 1\n",
    "            sentiment_label, sentiment_prob = get_sentiment(analyzer, tweet_text)\n",
    "            tweet['sentiment_label'] = sentiment_label\n",
    "            tweet['sentiment_prob'] = sentiment_prob\n",
    "            tweets_json.append(json.dumps(tweet, cls=DecimalEncoder))\n",
    "            # print(f'{i}: \\t{tweet_text}, \\n\\t{sentiment_label}, \\n\\t{sentiment_prob}')\n",
    "        except:\n",
    "            pass\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86132030c22f4560eeb593796c7a3aeacc840788af4f511ae49e43b2847bdc45"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('python-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
